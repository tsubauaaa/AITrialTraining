{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AITraining3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9G2ZhUMP3BU20yxMNbiKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsubauaaa/AITrialTraining/blob/main/Training3/AITraining3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvi8gKZ51qO",
        "outputId": "72ef4b60-95db-4f61-8edd-7f5cf94175bf"
      },
      "source": [
        " # Google Driveをマウントする\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_0hFdJwXF7w",
        "outputId": "972845d5-7ecb-4151-cd69-57e7b2113bae"
      },
      "source": [
        "# install MeCab\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        "# check path to \"ipadic-neologd\"\n",
        "!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"\n",
        "\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n",
            "/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1VKEi7usaW2"
      },
      "source": [
        "import json\n",
        "import gensim\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOnsQQhr5pky"
      },
      "source": [
        "decoder = json.JSONDecoder()\n",
        "all_datasets_list = []\n",
        "with open('/content/drive/My Drive/Colab Notebooks/AITraining/dataset_ja_dev.json') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        all_datasets_list.append(decoder.raw_decode(line)[0])\n",
        "        line = f.readline()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFfnpT1G6rpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1306c2fc-b1f9-4535-e1f0-effc3bc4a520"
      },
      "source": [
        "all_datasets_list[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'ja',\n",
              " 'product_category': 'wireless',\n",
              " 'product_id': 'product_ja_0821731',\n",
              " 'review_body': 'ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。',\n",
              " 'review_id': 'ja_0944897',\n",
              " 'review_title': '欠陥品',\n",
              " 'reviewer_id': 'reviewer_ja_0192786',\n",
              " 'stars': '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "04UlblNH7dBK",
        "outputId": "8acbe6a0-0be3-49b3-d6d4-cb8c2cc48c76"
      },
      "source": [
        "datasets_list = []\n",
        "for data in all_datasets_list:\n",
        "    review_body = data['review_body']\n",
        "    stars = data['stars']\n",
        "    datasets_list.append([review_body, stars])\n",
        "datasets = pd.DataFrame(datasets_list, columns = ['review_body' , 'stars'])\n",
        "datasets"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>新旧含めて4つのカーテンレールがあるのですが、使用出来るカーテンレールはありませんでした。 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>予約注文でしたが、どこから特典であるpdfダウンロードすればよいのでしょうか…</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>前のレビューにもありましたが、片方が全く動きません。 返品しようにも、なんだかめんどくさいし...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>ミニオンが好きで、息子に買いました。 親子で楽しく遊んでます。</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>まずレーザーの光が強いw 昔 ゲーセンで取ったヤツの3倍くらい 暗闇でレーザーの光が当たった...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>色もち、発色もよく、ティントによくある\"激しい唇の荒れ\"が少ないのでとても使いやすいなと思い...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1年前に別メーカーのバッテリーを交換して、使えましたが、スマホ確認のところで認識さらませんで...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>前なら剃った次の日はまた、ポツポツでそれを抜いてましたがポツポツがありません！</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            review_body stars\n",
              "0     味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込...     1\n",
              "1                ホームボタン周りの気泡が全く抜けません。 返金をお願いしましたが、断られた。     1\n",
              "2     新旧含めて4つのカーテンレールがあるのですが、使用出来るカーテンレールはありませんでした。 ...     1\n",
              "3               予約注文でしたが、どこから特典であるpdfダウンロードすればよいのでしょうか…     1\n",
              "4     前のレビューにもありましたが、片方が全く動きません。 返品しようにも、なんだかめんどくさいし...     1\n",
              "...                                                 ...   ...\n",
              "4995                    ミニオンが好きで、息子に買いました。 親子で楽しく遊んでます。     5\n",
              "4996  まずレーザーの光が強いw 昔 ゲーセンで取ったヤツの3倍くらい 暗闇でレーザーの光が当たった...     5\n",
              "4997  色もち、発色もよく、ティントによくある\"激しい唇の荒れ\"が少ないのでとても使いやすいなと思い...     5\n",
              "4998  1年前に別メーカーのバッテリーを交換して、使えましたが、スマホ確認のところで認識さらませんで...     5\n",
              "4999            前なら剃った次の日はまた、ポツポツでそれを抜いてましたがポツポツがありません！     5\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1UjH2W6yge"
      },
      "source": [
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "# param: dataset_list[]['review_body']\n",
        "# return: 分かちした単語のリスト\n",
        "def make_wakati(sentence):\n",
        "    # MeCabで分かち書き\n",
        "    sentence = tagger.parse(sentence)\n",
        "    # 半角全角英数字除去\n",
        "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
        "    # 記号もろもろ除去\n",
        "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
        "    # スペースで区切って形態素の配列へ\n",
        "    wakati = sentence.split(\" \")\n",
        "    # 空の要素は削除\n",
        "    wakati = list(filter((\"\").__ne__, wakati))\n",
        "    return wakati"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAOqxOpxhe6s",
        "outputId": "ce022ce0-8929-4c44-c696-b5b3bcd9b0e0"
      },
      "source": [
        "# w2vする\n",
        "w2v_model = gensim.models.Word2Vec.load('/content/drive/My Drive/Colab Notebooks/AITraining/w2v/w2v.model')\n",
        "word2vec = {}\n",
        "no_words = []\n",
        "for dataset in datasets_list:\n",
        "    wakati = make_wakati(dataset[0])\n",
        "    for word in wakati:\n",
        "        if word in word2vec:\n",
        "            continue\n",
        "        if word not in list(w2v_model.wv.vocab):\n",
        "            no_words.append(word)\n",
        "            continue\n",
        "        word2vec[word] = w2v_model.wv[word]\n",
        "print(len(word2vec))\n",
        "print(len(no_words))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12739\n",
            "711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Q4mAMD1xHs"
      },
      "source": [
        "# 単語をベクトルデータに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2vec(sentence):\n",
        "    wakati = make_wakati(sentence)\n",
        "    return torch.tensor([word2vec[w] for w in wakati])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egd-cKlV12PD"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
        "class LSTMRegressor(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, sentence):\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(sentence)\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        output = self.out(lstm_out[0].view(-1, self.hidden_dim))\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_DZmzN2Lac",
        "outputId": "2265c13f-cfd0-4765-d680-1860e1d292b0"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 128\n",
        "lstm = LSTMRegressor(EMBEDDING_DIM, HIDDEN_DIM)\n",
        "s1 = datasets_list[0][0]\n",
        "s2 = datasets_list[0][1]\n",
        "print(s1)\n",
        "# 味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込み も出来なかった。腹が立ってごみ箱行きでした。こんなものは２度と購入する気はない。 返品するのも交渉するのも、金額も金額だからと面倒くさがってしない方が多いのではないか？ 最初から不良品多しとでも表記しておいたら如何？\n",
        "print(make_wakati(s1))\n",
        "# ['味', '自体', '及び', '吸い', '心地', 'は', '良い', 'の', 'だ', 'が', '不', '良品', 'が', '多', '過ぎる', '私', 'の', '場合', '本', 'の', 'うち', '本', 'が', '蒸気', 'も', '出', 'ず', '吸い込み', 'も', '出来', 'なかっ', 'た', '腹', 'が', '立っ', 'て', 'ごみ箱', '行き', 'でし', 'た', 'こんな', 'もの', 'は', '度', 'と', '購入', 'する', '気', 'は', 'ない', '返品', 'する', 'の', 'も', '交渉', 'する', 'の', 'も', '金額', 'も', '金額', 'だ', 'から', 'と', '面倒く', 'さ', 'がっ', 'て', 'し', 'ない', '方', 'が', '多い', 'の', 'で', 'は', 'ない', 'か', '最初', 'から', '不', '良品', '多し', 'と', 'でも', '表記', 'し', 'て', 'おい', 'たら', '如何']\n",
        "\n",
        "inputs1 = sentence2vec(s1)\n",
        "print(inputs1)\n",
        "out = lstm(inputs1.view(len(inputs1), 1, -1))\n",
        "print(out)\n",
        "print(s2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "味自体及び吸い心地は良いのだが、不良品が多過ぎる。私の場合５本のうち２本が蒸気も出ず、吸い込み も出来なかった。腹が立ってごみ箱行きでした。こんなものは２度と購入する気はない。 返品するのも交渉するのも、金額も金額だからと面倒くさがってしない方が多いのではないか？ 最初から不良品多しとでも表記しておいたら如何？\n",
            "['味', '自体', '及び', '吸い', '心地', 'は', '良い', 'の', 'だ', 'が', '不', '良品', 'が', '多', '過ぎる', '私', 'の', '場合', '本', 'の', 'うち', '本', 'が', '蒸気', 'も', '出', 'ず', '吸い込み', 'も', '出来', 'なかっ', 'た', '腹', 'が', '立っ', 'て', 'ごみ箱', '行き', 'でし', 'た', 'こんな', 'もの', 'は', '度', 'と', '購入', 'する', '気', 'は', 'ない', '返品', 'する', 'の', 'も', '交渉', 'する', 'の', 'も', '金額', 'も', '金額', 'だ', 'から', 'と', '面倒く', 'さ', 'がっ', 'て', 'し', 'ない', '方', 'が', '多い', 'の', 'で', 'は', 'ない', 'か', '最初', 'から', '不', '良品', '多し', 'と', 'でも', '表記', 'し', 'て', 'おい', 'たら', '如何']\n",
            "tensor([[-0.4999, -0.6908, -2.5520,  ...,  1.2527, -0.7275,  0.6183],\n",
            "        [ 0.3367,  0.8707, -0.7007,  ...,  0.4871,  0.3114, -0.0030],\n",
            "        [ 1.1938, -0.3116,  0.3566,  ...,  2.1716,  1.3614, -1.0291],\n",
            "        ...,\n",
            "        [-0.6864, -1.0068,  1.2038,  ..., -1.4014, -1.4441,  1.2285],\n",
            "        [-0.6333, -2.3974, -0.3745,  ..., -1.2556, -2.5141, -1.6721],\n",
            "        [-0.1302,  0.5549,  0.0820,  ..., -1.7729, -0.4356,  0.1791]])\n",
            "tensor([[0.0280]], grad_fn=<AddmmBackward>)\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv1lVDDt38wy",
        "outputId": "5e8d4719-9593-4b77-8e69-2109da5f8cfb"
      },
      "source": [
        "len_datasets = len(datasets_list)\n",
        "# starsをtensorにする\n",
        "category2index = {}\n",
        "for i in range(len_datasets):\n",
        "    star = datasets_list[i][1]\n",
        "    if star in category2index: continue\n",
        "    category2index[star] = len(category2index)\n",
        "print(category2index)\n",
        "\n",
        "def category2tensor(star):\n",
        "    return torch.tensor([category2index[star]], dtype=torch.float)\n",
        "\n",
        "print(category2tensor(\"2\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
            "tensor([1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsoIFDE06TFP",
        "outputId": "fb461f3d-1ed2-425a-926f-8b9a065bffc8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "# 元データを7:3に分ける（7->学習、3->テスト）\n",
        "traindata, testdata = train_test_split(datasets, train_size=0.7, shuffle=True)\n",
        "# 単語のベクトル次元数\n",
        "EMBEDDING_DIM = 200\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# モデル宣言\n",
        "model = LSTMRegressor(EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
        "loss_function = nn.MSELoss()\n",
        "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 各エポックの合計loss値を格納する\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "    all_loss = 0\n",
        "    for review, star in zip(traindata[\"review_body\"], traindata[\"stars\"]):\n",
        "        # モデルが持ってる勾配の情報をリセット\n",
        "        model.zero_grad()\n",
        "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
        "        try:\n",
        "            inputs = sentence2vec(review).to(device)\n",
        "        except KeyError:\n",
        "            continue\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = model(inputs.view(len(inputs), 1, -1))\n",
        "        # 正解カテゴリをテンソル化\n",
        "        answer = category2tensor(star).to(device)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # 勾配をセット\n",
        "        loss.backward()\n",
        "        # 逆伝播でパラメータ更新\n",
        "        optimizer.step()\n",
        "        # lossを集計\n",
        "        all_loss += loss.item()\n",
        "    losses.append(all_loss)\n",
        "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
        "print(\"done.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 \t loss 5317.967649936757\n",
            "epoch 1 \t loss 4033.187906642862\n",
            "epoch 2 \t loss 3483.67838528345\n",
            "epoch 3 \t loss 2926.4702326237552\n",
            "epoch 4 \t loss 2542.100880317967\n",
            "epoch 5 \t loss 2105.488288227733\n",
            "epoch 6 \t loss 1737.4972628120784\n",
            "epoch 7 \t loss 1526.4240797292018\n",
            "epoch 8 \t loss 1294.956155272608\n",
            "epoch 9 \t loss 1033.9920587343122\n",
            "epoch 10 \t loss 885.817691732648\n",
            "epoch 11 \t loss 704.7961371352092\n",
            "epoch 12 \t loss 568.0442358971792\n",
            "epoch 13 \t loss 482.22400516949045\n",
            "epoch 14 \t loss 420.17195611822314\n",
            "epoch 15 \t loss 356.3754131910427\n",
            "epoch 16 \t loss 305.2684133986606\n",
            "epoch 17 \t loss 258.6660055110502\n",
            "epoch 18 \t loss 223.57395159684\n",
            "epoch 19 \t loss 203.39346838373945\n",
            "epoch 20 \t loss 176.56467351534553\n",
            "epoch 21 \t loss 152.5184159921095\n",
            "epoch 22 \t loss 125.98299751213143\n",
            "epoch 23 \t loss 107.58991707471597\n",
            "epoch 24 \t loss 92.54088241339088\n",
            "epoch 25 \t loss 80.26104997906734\n",
            "epoch 26 \t loss 71.87922615033379\n",
            "epoch 27 \t loss 66.84867324163491\n",
            "epoch 28 \t loss 62.32904485324491\n",
            "epoch 29 \t loss 59.17819523477175\n",
            "epoch 30 \t loss 54.92071744380033\n",
            "epoch 31 \t loss 46.601259240606694\n",
            "epoch 32 \t loss 42.89523427506069\n",
            "epoch 33 \t loss 40.60894558369998\n",
            "epoch 34 \t loss 36.73222624030777\n",
            "epoch 35 \t loss 29.87914739867455\n",
            "epoch 36 \t loss 25.785183691495803\n",
            "epoch 37 \t loss 23.288433983817797\n",
            "epoch 38 \t loss 21.640993103021017\n",
            "epoch 39 \t loss 21.818522394512602\n",
            "epoch 40 \t loss 20.91959092658044\n",
            "epoch 41 \t loss 20.04639646326352\n",
            "epoch 42 \t loss 18.46117254026966\n",
            "epoch 43 \t loss 17.519176781934007\n",
            "epoch 44 \t loss 16.239624198832914\n",
            "epoch 45 \t loss 14.967875308654229\n",
            "epoch 46 \t loss 13.6240284145819\n",
            "epoch 47 \t loss 13.01172662533179\n",
            "epoch 48 \t loss 11.410679968538787\n",
            "epoch 49 \t loss 10.851854097424678\n",
            "epoch 50 \t loss 10.352311930933354\n",
            "epoch 51 \t loss 9.268498816645195\n",
            "epoch 52 \t loss 9.051123220099395\n",
            "epoch 53 \t loss 7.985149244372991\n",
            "epoch 54 \t loss 7.530399127323001\n",
            "epoch 55 \t loss 6.746655388578123\n",
            "epoch 56 \t loss 6.422956115532333\n",
            "epoch 57 \t loss 5.943833831554333\n",
            "epoch 58 \t loss 5.3374214595519724\n",
            "epoch 59 \t loss 5.00420879944221\n",
            "epoch 60 \t loss 4.427083188412595\n",
            "epoch 61 \t loss 4.083563683685984\n",
            "epoch 62 \t loss 3.7065636620349416\n",
            "epoch 63 \t loss 3.379404247335504\n",
            "epoch 64 \t loss 3.2776219089278555\n",
            "epoch 65 \t loss 3.106483762381856\n",
            "epoch 66 \t loss 3.028019915695527\n",
            "epoch 67 \t loss 2.94616614267143\n",
            "epoch 68 \t loss 2.8827270761185844\n",
            "epoch 69 \t loss 2.6810845570569093\n",
            "epoch 70 \t loss 2.614494128126026\n",
            "epoch 71 \t loss 2.398629946371017\n",
            "epoch 72 \t loss 2.2668127814715042\n",
            "epoch 73 \t loss 2.132676288449364\n",
            "epoch 74 \t loss 2.066353159927626\n",
            "epoch 75 \t loss 1.919536941710792\n",
            "epoch 76 \t loss 1.7971485861808318\n",
            "epoch 77 \t loss 1.6564744905477546\n",
            "epoch 78 \t loss 1.5545912369846313\n",
            "epoch 79 \t loss 1.3876609637897346\n",
            "epoch 80 \t loss 1.3298851359136492\n",
            "epoch 81 \t loss 1.2358444563086515\n",
            "epoch 82 \t loss 1.2311475368181526\n",
            "epoch 83 \t loss 1.1794340999231387\n",
            "epoch 84 \t loss 1.14379065202575\n",
            "epoch 85 \t loss 1.0602267052579748\n",
            "epoch 86 \t loss 1.0054914210221817\n",
            "epoch 87 \t loss 0.927189262478926\n",
            "epoch 88 \t loss 0.8690328305206876\n",
            "epoch 89 \t loss 0.8042303243722557\n",
            "epoch 90 \t loss 0.7678824367377821\n",
            "epoch 91 \t loss 0.7122420579940432\n",
            "epoch 92 \t loss 0.6968041874790778\n",
            "epoch 93 \t loss 0.6510336744292538\n",
            "epoch 94 \t loss 0.6364167183497962\n",
            "epoch 95 \t loss 0.6186799709451236\n",
            "epoch 96 \t loss 0.6121941445070114\n",
            "epoch 97 \t loss 0.6171512580744505\n",
            "epoch 98 \t loss 0.6306529307112179\n",
            "epoch 99 \t loss 0.6439860150805679\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "F1OrN0w07AA0",
        "outputId": "df10fed9-ff89-4164-c5aa-12424f261aa7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(losses)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f014c4371d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0HAS8SmI5kR",
        "outputId": "b360f9e2-b0b1-4e3f-9a98-6fd99c9fa2d0"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# テストデータの母数計算(1500)\n",
        "test_num = len(testdata)\n",
        "skip_num = 0\n",
        "# 正解の件数\n",
        "match = 0\n",
        "# 絶対誤差用\n",
        "y_preds = []\n",
        "y_true = []\n",
        "# 勾配自動計算OFF\n",
        "with torch.no_grad():\n",
        "    for review, star in zip(testdata[\"review_body\"], testdata[\"stars\"]):\n",
        "        # テストデータの予測\n",
        "        try:\n",
        "            inputs = sentence2vec(review).to(device)\n",
        "        except KeyError:\n",
        "            skip_num += 1\n",
        "            continue\n",
        "        out = model(inputs.view(len(inputs), 1, -1))\n",
        "        y_preds.append(out.item())\n",
        "        y_true.append(int(star))\n",
        "\n",
        "        # outを四捨五入して一致数を数える\n",
        "        predict = torch.round(out).to(device)\n",
        "        if predict < 0:\n",
        "            predict = torch.tensor(0).to(device)\n",
        "        elif predict > 4:\n",
        "            predict = torch.tensor(4).to(device)\n",
        "\n",
        "        answer = category2tensor(star).to(device)\n",
        "        if predict == answer:\n",
        "            match += 1\n",
        "tested_num = test_num - skip_num\n",
        "mae = mean_absolute_error(y_true, y_preds)\n",
        "print(f\"Correct answer rate: {match / tested_num}, match: {match}, tested_num: {tested_num}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct answer rate: 0.3368660105980318, match: 445, tested_num: 1321\n",
            "Mean Absolute Error: 1.2965448602503848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ONhxHb6K0b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}